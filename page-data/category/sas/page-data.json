{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/category/sas/","result":{"data":{"remark":{"posts":[{"post":{"html":"<p>This release contains a number of small fixes and UI improvements, and two major features:</p>\n<ul>\n<li>Extended Data Validations</li>\n<li>Native Postgres Support</li>\n</ul>\n<h2>Extended Data Validations</h2>\n<p>In the <a href=\"/3-12-four-new-data-management-features\">previous release</a> we provided a feature that allows a SAS developer to create a program (using the source row as input) to determine the values of a particular dropdown.</p>\n<p>This feature has now been extended, to allow the response to contain dropdowns for other cells in the same row.  Default values can also be provided for each additional dropdown.</p>\n<p><div class=\"gatsby-resp-iframe-wrapper\" style=\"padding-bottom: 56.53333333333334%; position: relative; height: 0; overflow: hidden; margin-bottom: 1.0725rem\" > <div class=\"embedVideo-container\"> <iframe title=\"Retain Formulas when Loading Excel to SAS\" src=\"https://www.youtube.com/embed/rmES77aIr90?rel=0\" class=\"embedVideo-iframe\" style=\"border:0; position: absolute; top: 0; left: 0; width: 100%; height: 100%; \" loading=\"eager\" allowfullscreen=\"\" sandbox=\"allow-same-origin allow-scripts allow-popups\"></iframe> </div> </div></p>\n<p>To make this work, the SAS developer simply needs to write a SAS program that takes a source table named <code>work.source_row</code> (the row being edited) and creates two output tables:</p>\n<ul>\n<li><code>work.dynamic_values</code> - the first dropdown</li>\n<li><code>work.dynamic_extended_values</code> - the additional dropdowns, and any defaults.</li>\n</ul>\n<p>Your SAS Program (hook script) can be a file on the filesystem (in which case it must end with \".sas\") or it can also be a Stored Process or Viya Job in the logical folder tree (metadata or SAS Drive) - in which case it must <em>not</em> end with \".sas\".  In both cases you should provide the full path and filename in the MPE_VALIDATIONS table.</p>\n<p>More info in <a href=\"https://docs.datacontroller.io/dynamic-cell-dropdown\">documentation</a>.</p>\n<h2>Native Postgres Support</h2>\n<p>Alongside Redshift and SQL Server we now have native support for Postgres.  What does this mean?</p>\n<p>Thanks to SAS/ACCESS engines, we can automatically support a very wide range of database engines.  However load times can become significant when the target contains millions (or billions) of rows.</p>\n<p>In order to provide \"native\" support we update our load process to 'inject' a temporary table using SQL passthrough, which results in significantly faster updates for certain load types, such as SCD2.</p>\n<hr>\n<p>Did you know Data Controller (Community Edition) is free, for unlimited users? <a href=\"/contact\">Contact us</a> for your copy!</p>","fields":{"slug":"/3-13-extended-data-validation/"},"frontmatter":{"title":"v3.13 Release: Extended Data Validation and Native Postgres Support","date":"September 06, 2021","author":"Allan Bowe","authorLink":"https://www.linkedin.com/in/allanbowe/","previewImg":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/bfce32db5dd470a53868f5677c65fb54/7934d/validation1.png","srcSet":"/static/bfce32db5dd470a53868f5677c65fb54/f582d/validation1.png 882w,\n/static/bfce32db5dd470a53868f5677c65fb54/b5dd3/validation1.png 1763w,\n/static/bfce32db5dd470a53868f5677c65fb54/7934d/validation1.png 3526w","sizes":"(min-width: 3526px) 3526px, 100vw"},"sources":[{"srcSet":"/static/bfce32db5dd470a53868f5677c65fb54/c916e/validation1.webp 882w,\n/static/bfce32db5dd470a53868f5677c65fb54/8b9a2/validation1.webp 1763w,\n/static/bfce32db5dd470a53868f5677c65fb54/2e8b1/validation1.webp 3526w","type":"image/webp","sizes":"(min-width: 3526px) 3526px, 100vw"}]},"width":3526,"height":1710}}}}}},{"post":{"html":"<p>Data Controller was implemented at Siemens Healthineers to facilitate their SAS-Powered Smart Data Catalog and integrate with Data Lineage reporting. We are grateful to <a href=\"https://www.linkedin.com/in/helen-stark-5bb15b6a/\">Helen Stark</a> (Power User) and <a href=\"https://www.linkedin.com/in/hans-juergen-kopperger-942634b7/\">Hans-Juergen Kopperger</a> (SAS App Developer) for sharing their \"before and after\" experiences. The previous article in this series is available <a href=\"/der-touristik/\">here</a>.</p>\n<hr>\n<h2>Helen Stark<a href=\"https://www.linkedin.com/in/helen-stark-5bb15b6a/\"><img class=\"alignright wp-image-1171\" src=\"/wp-content/uploads/2020/08/thumbnail_HStark.jpg\" alt=\"\" width=\"150\" height=\"200\" /></a></h2>\n<h3>Hi Helen, it’s great to meet with you today. Can you tell us - what is your role within the business?</h3>\n<p>I am the portfolio manager. What I do is a lot of demand management. So when people have new requests, like they want new data into our data lake, or they want it structured, or they want it visualized then I manage all that. For the Americas region, for North and south America. And I also do road shows, like marketing kind of aspect for the data scientists. And I do a smidge of project management here and there.</p>\n<h3>Interesting. And what do you actually use Data Controller for?</h3>\n<p>I use it to keep our Smart Data Catalog up to date. One of the things that I do is we have marketing posters, and so I put the links to those marketing posters in there so they are a part of our front end web design. And I also do the marketing videos, so adding those links. So really it’s just adding and deleting entries into Data Controller, so that our Smart Data Catalog is updated at all times.</p>\n<h3>And that Smart Data Catalog is in SAS. Is there reason its in SAS, and not say - Excel? Is it used by other parts of the business?</h3>\n<p>Yes, it’s used by the entire business</p>\n<h3>I see. And what is the Smart Data Catalog?</h3>\n<p>It's a listing of all of the offerings that data governance has. So, I say data governance but its data governance and analytical services. So, we are the data owners for all of the data in the company. It’s the single source of truth for all Siemens health business data. And we use Data Controller to manage that. And Data Controller does some incredible things that I do not understand – such as being able to stage and preview the data before it’s made publicly available. I mean I honestly don’t understand it but it does some miraculous things.</p>\n<h3>Nice feedback! Next question. How does Data Controller make your life easier?</h3>\n<p>Because it's so easy to use. Before we used an excel spreadsheet and it was quite unwieldy and it was bulky and it was so easy to make mistakes, just trying to remember where you were. And with Data Controller I love that I can filter first and get to exactly where I want to be and then I can edit. So, it really lessens the chance of me making a mistake. I love that, I am an editor, I am not an approver, but I like so I make an edit, but then it goes to an approver, so it’s like the four eye principle, something we did not have before. You can track changes, that’s amazing. Yeah, it made everything easier so whereas before I would dread updating the Smart Data Catalog, now you go in and it’s done in like 3 to 5 minutes.</p>\n<h3>Superb. Ok, before Data Controller came along, how did you get data into SAS?</h3>\n<p>So again, it was the foundation of this spreadsheet. You would have to check it out so there was some control over it. If somebody checked it out then nobody else could go in and make any changes, and you would have to wait for it to be checked back in and then run like a macro or some tool and then you could upload it and you could update your smart data search. It was a process that depended on how careful your co-workers were about remembering to check it back in. In short, it used to often take days to update the SAS environment, and now it takes minutes.</p>\n<h3>Wow - that’s great to hear! Ok, Next up. What are your favourite Data Controller features and why?</h3>\n<p>The filter. It will always be my favourite; it will never change. That’s really helpful. I just like how it makes it so much harder to make a mistake. With Data Controller it’s much harder to make a mistake. It’s less prone to human error. And the copy and paste is so easy, and yeah, there is nothing about it that I don’t love.</p>\n<h3>Brilliant, I think that’s the best feedback we’ve ever had.</h3>\n<p>Really, I mean it has made our lives so much easier, so much faster. Um yeah, I just love it.</p>\n<h3>Thankyou so much!</h3>\n<hr>\n<h2>Hans-Juergen <a href=\"https://www.linkedin.com/in/hans-juergen-kopperger-942634b7/\"><img class=\"alignright wp-image-1181\" src=\"/wp-content/uploads/2020/08/0-1-1.jpeg\" alt=\"Hans-Juergen\" width=\"150\" height=\"225\" /></a></h2>\n<h3>Guten Morgen Hans-Juergen! Can you tell us a little about your role within the business?</h3>\n<p>Yes, I am working as a Data Integration Manager at Siemens Healthineers providing BI and Analytical Services for our colleagues. My department is the DGA - Data Governance and Analytical Services. At Siemens-Healthineers we are analyzing \"Big Data\" from our computer systems - AT Angiography and Therapy, Computer Tomography CT, MR Magnetresonanz Tomography, and LD Labordiagnostik.</p>\n<p>In consequence of our Business Strategy \"from Onsite to Online\" our focus is to connect more and more systems to our BI backend. With new services like \"Condition-based Maintenance\" or \"Predictive Analysis\", we can now generate data-driven services to increase business values for our customers or even decrease our overall service costs.</p>\n<p>Our BI platform is based on the SAS technology stack. To get our Business Analysts and Data Scientists nearer to our Data Lake I have created a Smart Data Catalog which is an interactive web application with a \"google style\" search facility. Now they can do their jobs more effectively without struggling to find and access accurate, complete, and trustworthy data. As a result, they spend less time searching for data and can actually focus on using data to generate analyses and impactful insights.</p>\n<h3>Now that's valuable! And what do you use Data Controller for?</h3>\n<p>To increase Data Quality while uploading backend data into our BI platform. Data Controller provides “data version control”, and full traceability of changes. We have several control tables that provide data for web applications like the \"Smart Data Catalog\", and with Data Controller it's now an easy, controllable and manageable process to get these changes into the backend tables.</p>\n<p>In the past we had a custom Stored Process web app for uploading excel files, based on an excel template. This process had negative consequences for Data Quality because it often happened that many different versions of the excel templates were created and in the end we didn't know which was the latest version and which values we wanted to upload into the system. It could take a lot of time to clarify who had done which upload.</p>\n<p>I would often receive support tickets in relation to this upload, the cause of which was often due to the diversity of our excel templates, and being unsure which was the right template...So, we would have a lot of discussions about how to bring data into the backend in a controlled manner.</p>\n<p>Then one day, I got information through <a href=\"https://sasusergroup.de/\">SAS User Group Germany</a> that you provide a solution with Data Controller. I was initially interested in the <a href=\"https://docs.datacontroller.io/videos/#data-lineage\">Data Lineage</a> functionality, but then I understood the main concept behind Data Controller. And for me the main benefit is that I can save a lot of time - with out of the box features like the web data editor, and the web upload facility with excel spreadsheet drag and drop. And there is the automatic workflow behind with the mandatory approval step. Since we implemented Data Controller, we no longer get those support tickets.</p>\n<h3>Fantastic. If you had to pick your top features, what would they be?</h3>\n<p>The main benefit is getting data controlled, and into the backend. The controlled process, and the approval process, those are the main benefits. But we've got other benefits. For instance, we have Data Lineage now. The Data Lineage diagrams could also be linked directly from our Smart Data Catalog using URL parameters. This easy integration means our users can open the relevant page in Data Controller with one click.</p>\n<p>The transparency of the history page is another benefit. I can look at every requested submit or approval - what changes have been applied, what changes have been submitted, and what changes have been approved. This helps us a lot to get data transparency.</p>\n<p>The <a href=\"https://docs.datacontroller.io/emails/\">email alerts</a> is a great feature. For the communication of changes, we had previously created a team's collaboration chat. e.g. if someone did a change and needed to request an approval. But with email alerts, the notification of changes is now automatically sent to the responsible data owner, who can immediately click the email link and do his approval. This speeds up the whole process.</p>\n<p>Another advantage is the \"database approach\" for updates. So, someone is changing one row in a table which is connected to his use case, another guy can change other rows of the same table, nearly simultaneously. Because not everyone is changing the same rows. Everyone has their own subset of rows, their own \"workspace\" within one table. In the past we would have one excel template, and this would always override all values. We would have a lot of excel templates going around our colleagues, so there were always conflicts of overrides and versioning, and stuff like that. With Data Controller, it's now a simple, easy and transparent data capture process.</p>\n<h3>Vielen Dank!</h3>\n<hr>\n<div class=\"imgHolder\">\n  <a href=\"/blog\">\n    <img class=\"wp-image-1190 size-large aligncenter\" src=\"/wp-content/uploads/2020/08/Get-Started-Smart-Data-Catalog.png\" alt=\"Smart Data Catalog\" />\n    <div>Smart Data Catalog</div>\n  </a>\n</div>","fields":{"slug":"/siemens-healthineers-smart-data-catalog/"},"frontmatter":{"title":"Siemens Healthineers Smart Data Catalog and Data Controller","date":"August 24, 2020","author":"Allan Bowe","authorLink":"https://www.linkedin.com/in/allanbowe/","previewImg":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/3fa98b7c15a2f6a7600a40df10a0df34/948c1/siemenshealthineers.png","srcSet":"/static/3fa98b7c15a2f6a7600a40df10a0df34/f95d8/siemenshealthineers.png 144w,\n/static/3fa98b7c15a2f6a7600a40df10a0df34/3fffe/siemenshealthineers.png 288w,\n/static/3fa98b7c15a2f6a7600a40df10a0df34/948c1/siemenshealthineers.png 576w","sizes":"(min-width: 576px) 576px, 100vw"},"sources":[{"srcSet":"/static/3fa98b7c15a2f6a7600a40df10a0df34/13995/siemenshealthineers.webp 144w,\n/static/3fa98b7c15a2f6a7600a40df10a0df34/7ee31/siemenshealthineers.webp 288w,\n/static/3fa98b7c15a2f6a7600a40df10a0df34/27686/siemenshealthineers.webp 576w","type":"image/webp","sizes":"(min-width: 576px) 576px, 100vw"}]},"width":576,"height":144}}}}}},{"post":{"html":"<p>The Sarbanes-Oxley Act of 2002 has applied to all publicly-traded companies doing business in the US since 2006. The penalties can be severe - if Uncle Sam considers a corporate officer to have deliberately submitted an inaccurate certification, the corporate fine is $5 million with up to twenty years in prison for the individual(s). Accidental mis-certification (or non-submission) is just $1 million and 10 years in prison.</p>\n<p>There are many aspects to full Sarbanes-Oxley (SOX) compliance, the <a href=\"https://www.govinfo.gov/content/pkg/BILLS-107hr3763enr/pdf/BILLS-107hr3763enr.pdf\">legislation</a> is over 60 pages long. As with other regulatory obligations, the goal is to regularly provide enough evidence to satisfy the auditor that the requirements have been met. As anyone running a compliance team knows, this is no small endeavour. The ability to automate the generation of such evidence, or make it available automatically to auditors, can result in significant cost savings. This article breaks down the areas where Data Controller can contribute to satisfying the requirements of the Sarbanes-Oxley Act.</p>\n<h2>Sarbanes-Oxley Act Section 404 - MANAGEMENT ASSESSMENT OF INTERNAL CONTROLS.</h2>\n<p>Data Controller facilitates internal controls through a 4 eyes review &#x26; approve mechanism for data changes. This, combined with data validation and an integrated workflow feature, provides a mechanism to easily track and report on the number of internal controls (quality rules, signoffs, rejections), as well as the frequency they are applied, who is applying them, which data items the controls relate to, and who is performing them. Such metrics can be compared and contrasted with pre-existing and current quality measures to help determine control effectiveness. Variations in the number of submit / approve cycles between reporting teams, also provide objective and repeatable measurements to support the assessment of the effectiveness of internal controls.</p>\n<div class=\"imgHolder\"><a href=\"https://www.govinfo.gov/content/pkg/BILLS-107hr3763enr/pdf/BILLS-107hr3763enr.pdf\"><img class=\"wp-image-1105 size-full aligncenter\" title=\"Sec 404. (Sarbanes-Oxley)\" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-07-17-57-01.png\" alt=\"Sarbanes Oxley\"/></a><caption>Sarbanes Oxley</caption></div>\n<p>  Section 404 is widely considered the most onerous part of Sarbanes-Oxley, as the documentation and testing of all the controls requires significant time and effort. To address this, the <a href=\"https://pcaobus.org/\">Public Company Accounting Oversight Board</a> (PCAOB - a US non-profit created by the Sarbanes-Oxley act itself) released<a href=\"https://pcaobus.org/Rulemaking/Docket%20021/2007-06-12_Release_No_2007-005A.pdf\"> additional guidance</a> to assist management and auditors in producing their reports. This is officially labeled \"Auditing Standard No. 5 - <em>An Audit of Internal Control Over Financial Reporting That Is Integrated with An Audit of Financial Statements\"</em> A few points are highlighted by the guidance in this standard that are pertinent to users of Data Controller. <h2>PCAOB AS5 Sec24 - Controls Over Management Override</h2> Management Overrides (the freedom to simply \"replace\" reporting figures based on, presumably, sound judgement) are entity level controls that can be easily captured (in a centralised manner) by Data Controller. This in fact, is the \"core functionality\" of the tool. Data Stewards / Data Processors (Editors) make the change, then one or more Data Owners / Data Controllers (Approvers) sign it off before it is applied to the target table. A copy of the original excel file (if used) and a record of who made the change, when, what the change was, and why (if a reason is provided) is recorded. <a href=\"https://docs.datacontroller.io/dcc-validations/\">Data Validation</a> rules can also be defined to ensure that inputs fit the desired pattern(s). <a href=\"https://pcaobus.org/Rulemaking/Docket%20021/2007-06-12_Release_No_2007-005A.pdf\"><img class=\"aligncenter wp-image-1122\" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-10-10-41-12.png\" alt=\"Sarbanes Oxley sas management overrides\" width=\"887\" height=\"409\" /></a> For fun, we made a short video for this part:</p>\n<p><div class=\"gatsby-resp-iframe-wrapper\" style=\"padding-bottom: 56.53333333333334%; position: relative; height: 0; overflow: hidden; margin-bottom: 1.0725rem\" > <div class=\"embedVideo-container\"> <iframe title=\"\" src=\"https://www.youtube.com/embed/iY3KQZL4ok0?rel=0\" class=\"embedVideo-iframe\" style=\"border:0; position: absolute; top: 0; left: 0; width: 100%; height: 100%; \" loading=\"eager\" allowfullscreen=\"\" sandbox=\"allow-same-origin allow-scripts allow-popups\"></iframe> </div> </div></p>\n<p>  <h2>PCAOB AS5 Sec27 - Identifying Entity-Level Controls</h2> <img class=\"aligncenter wp-image-1126\" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-10-12-58-26.png\" alt=\"Sarbanes Oxley SAS Section 24\" width=\"792\" height=\"198\" /> In the area of documenting the inputs, transformations and outputs of data flows within an organisation, SAS particularly shines, especially in the version 9 world. The table and column level lineage generated by SAS Data Integration provides a highly detailed view of the data lineage. Below is an example of Table level lineage, which colour codes each table according to it's library and captures the detail of each SAS job along the way. Clicking on a job will open the job in the metadata viewer. Clicking the table will open the table in VIEW mode. The lineage is shown all the way from source to target(s), or target to source(s) and can be exported in PNG, SVG, or CSV format.</p>\n<div class=\"imgHolder\"><img class=\"aligncenter\" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-10-14-41-04.png\" alt=\"SAS Table Level Lineage Sarbanes Oxley\"/><caption>SAS Table Level Lineage</caption></div>\n<p>Below is an example of column level lineage. Like Table Level lineage, this can be performed forwards or backwards and exported in multiple formats. Each arrow represents a SAS transform. Where business logic is applied, this is additionally extracted and showed in red.</p>\n<div class=\"imgHolder\"><img class=\"aligncenter\" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-10-18-42-50.png\" alt=\"SAS Column Level Lineage Sarbanes Oxley\"/><caption>SAS Column Level Lineage</caption></div>\n<p>  The ability to define additional data lineages, outside of SAS (eg between spreadsheets or other reporting systems) is in the product roadmap, along with lineage from SAS Viya. <h2>PCAOB AS5 App B - Benchmarking of Automated Controls</h2> The use of IT secured financial controls can significantly reduce the cost of Sarbanes-Oxley compliance testing following the first year assessment, particularly where the source code is secured and cannot be modified by users. The core programs (services) within the Data Controller application that perform data signoffs are mature, distinct and change tracked - so it is possible for Data Controller to be upgraded in-place without affecting the benchmarking strategy. This contrasts with spreadsheet based control mechanisms, which must be revalidated in each reporting period.</p>\n<div class=\"imgHolder\"><a href=\"https://pcaobus.org/Rulemaking/Docket%20021/2007-06-12_Release_No_2007-005A.pdf\"><img class=\"aligncenter\" title=\"PCAOB Release 2007-005A, Appendix B\" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-08-22-15-50.png\" alt=\"Sarbanes Oxley SAS\"/></a><caption>PCAOB Release 2007-005A, Appendix B</caption></div>\n<h2>Sarbanes-Oxley Act Section 1102 - Tampering</h2>\n<p>Coming back to the original 2002 SOx paper, there is an additional stick being waved against those who destroy records. This is, unfortunately, a common occurrence in DWh landscapes - poorly designed data models often result in frequent rebuilds of monthly datamarts when issues are found. If your BI / ETL teams are routinely destroying / modifying database records as part of regular work efforts, you might wish to: a) ensure there is a well documented ticketing system to make sure those individuals are protected from any accusations, or b) implement a <a href=\"/bitemporal-historisation-and-the-sas-dds/\">Bitemporal</a> data model to ensure a full and transparent version history of data is always kept regardless of rebuilds. IT-secured tools such as Data Controller enable auditors to see easily for themselves who has changed a record, when, why, and who signed it off - thereby vastly reducing the potential for unintentionally impeding an investigation.</p>\n<div class=\"imgHolder\"><a href=\"/wp-content/uploads/2020/08/BILLS-107hr3763enr.pdf\"><img class=\"aligncenter size-full\" title=\"SEC. 1102. (Sarbanes Oxley)\" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-07-20-18-21.png\" alt=\"sarbanes oxley SAS\"/></a><caption>SEC. 1102. (Sarbanes Oxley)</caption></div>\n<h2>Sarbanes Oxley and SAS</h2>\n<p>We chose SAS as the platform on which to build Data Controller as it is very reliable, provides excellent support for data drivers (enables our code to run inside almost any database), long term customer support, and is very easy to deploy against. The demo version of Data Controller can be <a href=\"https://docs.datacontroller.io/videos/#deploying-data-controller\">deployed in under 30 seconds</a> (on a SAS 9 platform).</p>\n<p>With SAS there are no additional servers to provision, firewalls to configure, scaling issues to address - everything works \"out of the box\". SAS also integrates nicely with existing enterprise authentication mechanisms such as LDAP, and the platform is typically fully secured under your existing IT policies at the backend.</p>\n<p>Data Controller is built on <a href=\"https://sasjs.io\">SASjs</a> and hence we have versions for both SAS 9 and Viya. Do <a href=\"/contact/\">get in touch</a> to learn more.</p>","fields":{"slug":"/sarbanes-oxley/"},"frontmatter":{"title":"Sarbanes-Oxley and Data Controller for SAS©","date":"August 12, 2020","author":"Allan Bowe","authorLink":"https://www.linkedin.com/in/allanbowe/","previewImg":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6bcf8e236f35ef8dddb0bb9907cfbf89/01df5/Screenshot-from-2020-08-10-19-16-01.png","srcSet":"/static/6bcf8e236f35ef8dddb0bb9907cfbf89/85096/Screenshot-from-2020-08-10-19-16-01.png 318w,\n/static/6bcf8e236f35ef8dddb0bb9907cfbf89/4b32c/Screenshot-from-2020-08-10-19-16-01.png 636w,\n/static/6bcf8e236f35ef8dddb0bb9907cfbf89/01df5/Screenshot-from-2020-08-10-19-16-01.png 1272w","sizes":"(min-width: 1272px) 1272px, 100vw"},"sources":[{"srcSet":"/static/6bcf8e236f35ef8dddb0bb9907cfbf89/464fd/Screenshot-from-2020-08-10-19-16-01.webp 318w,\n/static/6bcf8e236f35ef8dddb0bb9907cfbf89/afe36/Screenshot-from-2020-08-10-19-16-01.webp 636w,\n/static/6bcf8e236f35ef8dddb0bb9907cfbf89/24eb4/Screenshot-from-2020-08-10-19-16-01.webp 1272w","type":"image/webp","sizes":"(min-width: 1272px) 1272px, 100vw"}]},"width":1272,"height":718}}}}}},{"post":{"html":"<p>We caught up with <a href=\"https://www.linkedin.com/in/herbert-gro%C3%9Fmann-53690517a/\">Herbert Grossmann</a> of DER Touristik to understand how Data Controller for SAS is used within the BICC and the types of challenges it solves. <a href=\"https://www.linkedin.com/in/herbert-gro%C3%9Fmann-53690517a/\"><img class=\" wp-image-1137 alignright\" src=\"/wp-content/uploads/2020/08/0-1.jpeg\" alt=\"\" width=\"183\" height=\"183\" /></a> The previous article in this series can be found <a href=\"/data-controller-developer-perspective/\">here</a>. <h2>Guten Tag, Herby! Can you tell us about your role within DER Touristik?</h2> Yes, I am working here as project manager for BI and Analytics and my department is the BICC (Business Intelligence Competence Centre), and we have an absolute focus on the SAS technology stack - so that’s my daily business. <h2>Great. And, I understand you guys are using Data Controller for SAS. What do you use it for?</h2> Well, mainly for managing control tables, that we have a lot of nowadays, in the data warehouse. But we also implemented what we call an \"early bird booking system\". There we have used the Approval process within Data Controller, which is excellent, because users, business departments etc, can approve data that would normally only be accessible within the back-end warehouse itself. So now they have an interface, which limits their access to specific views, and this is very useful - it was also highly commended by our management. <h2>So, business users can approve modifications to secure warehouse tables without having direct write-access themselves?</h2> Exactly <h2>Fantastic. Next question. How does having Data Controller make your life easier?</h2> Well - there is the version control of course, that gives us a much better traceability of changes to see what was changed by whom, at what time. And we have the immediate constraint checking which is also very useful because some of the tables are sensitive towards, let’s say, the changes of the primary key. And in the past when we did it the \"old fashioned way\" it was possible that by mistake that someone could cause duplicate primary keys or stuff like that, so this is now not possible anymore, which is very good. And like the example that I mentioned before, that now we can grant access to certain sensitive tables even for business users that would normally have no access, but we can decide whether to give them at least the right to <em>view</em> these tables, or during special events <em>edit</em> tables, or approve edits of those tables. So this gives a lot of opportunities, and makes it much easier than it was in the past. <h2>Nice! And so, talking about the past, before you had Data Controller, how did you manage modifications to data in SAS?</h2> We classically used two approaches - on one hand using SAS Enterprise Guide to directly edit tables or do imports, such as imports of excel sheets for example. On the other hand, we have some batch processes that also do imports of Excel tables or CSV tables. So those were the classic and standard ways. And of course especially the batch one we are still using for some files, depending on the situation. But we do no editing of tables directly with Enterprise Guide anymore because it is much safer and easier to use the Data Controller. <h2>Understood. So on the Data Controller side, what would you say were your favourite features and why?</h2> I would say that I like the editor as a whole very much. I think that is great that in the moment you make a table editable, you can define the ways in which you would edit the tables. Like whether there is some historic logging or not, and the fact you can set the constraints. And in the editor then you have a lot of Data Quality opportunities such as defining drop-down lists for certain attributes, which really makes editing the tables easier and much more comfortable. It was a little bit of a pain in the past but now it’s almost fun. <h2>That's great feedback! Is there anything else, any comments you would like to add?</h2> Yes, I like the fact that Data Controller is really just a part of the SAS environment. It’s not a completely separate application that you have to install somewhere, but a kind of pluggable part of the SAS environment. I liked it very much because then you still have everything in your hands. I mean I am not a developer but my knowledge of SAS is already enough to match the criteria to be able to handle the Data Controller as whole, to even do the updates and/or to modify things. And also it’s easy to show others who have experience with SAS how the tool works and what is to be done when there are data issues. And yeah, I think that’s a big advantage. <img class=\"wp-image-1140 aligncenter\" src=\"/wp-content/uploads/2020/08/Group-1dt-1-e1597092362693.png\" alt=\"SAS DER Touristik\" width=\"242\" height=\"213\" /></p>","fields":{"slug":"/der-touristik/"},"frontmatter":{"title":"Data Controller - a BICC perspective","date":"August 10, 2020","author":"Allan Bowe","authorLink":"https://www.linkedin.com/in/allanbowe/","previewImg":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/65ef577f76c9ed7ba6a2816ffe8962c3/026c5/Group-1dt.png","srcSet":"/static/65ef577f76c9ed7ba6a2816ffe8962c3/1cc48/Group-1dt.png 219w,\n/static/65ef577f76c9ed7ba6a2816ffe8962c3/fe261/Group-1dt.png 438w,\n/static/65ef577f76c9ed7ba6a2816ffe8962c3/026c5/Group-1dt.png 875w","sizes":"(min-width: 875px) 875px, 100vw"},"sources":[{"srcSet":"/static/65ef577f76c9ed7ba6a2816ffe8962c3/d8972/Group-1dt.webp 219w,\n/static/65ef577f76c9ed7ba6a2816ffe8962c3/360f3/Group-1dt.webp 438w,\n/static/65ef577f76c9ed7ba6a2816ffe8962c3/e6409/Group-1dt.webp 875w","type":"image/webp","sizes":"(min-width: 875px) 875px, 100vw"}]},"width":875,"height":768}}}}}},{"post":{"html":"<p>Does the SAS DDS support Bitemporal historisation? Why yes indeed, with the right transform and extract logic, and updates to the primary keys.</p>\n<p>The SAS Detailed Data Store (DDS) suite provides \"out of the box\" data models for industries such as Banking, Insurance and Telco. They arrive with logical and physical models (eg in Erwin format), and a set of DDL files for your preferred database. These assets help to accelerate the delivery and deployment of a company data warehouse that has the further advantage of standardised integration with SAS Solution offerings. The model is also very large. It is highly likely that much of the model will be unused, especially in industries like insurance - where corporate structures, regulatory environments, and product offerings can be quite diverse.</p>\n<p>As a \"baseline\" model then, another way to utilise it is to take it as just that - a model, that provides guidance on putting together a warehouse that suits you, the customer. There is nothing to stop you picking &#x26; choosing the parts you like, that make sense for your particular use case(s).</p>\n<h2>The Validity of SCD2</h2>\n<p>The historisation approach in the DDS is based on the \"VALID_FROM_DTTM\" and \"VALID_TO_DTTM\" columns. These provide the open and close datetime pairs representing the 'validity' of the record. This - is where the confusion begins.</p>\n<p>What is 'validity'? Perhaps this represents the 'truth', eg the number of widgets we sold last month. So what is this truth? Is it the state of the database (transaction datetimes) between the 1st and the end of the month? Or does it represent the current view of last months widget sales, which were finally loaded on, say, the 15th of the following month? Dealing with this scenario (late arriving records) poses a number of challenges for the SCD2 model:</p>\n<ul>\n<li>Reloading historical data (as records must be physically removed, in order to reload)&#x3C;</li>\n<li>Loading corrections (again, records must first be removed)&#x3C;</li>\n<li>Maintaining an audit history, or even <em>the ability to run the same query twice and get the same result.</em></li>\n</ul>\n<p>An emerging consensus from the datawarehousing domain is the use of bitemporal datetime ranges for managing such requirements. The below article borrows heavily from <a href=\"/wp-content/uploads/2020/08/hist-op_1.1.6_en_manual.pdf\">this excellent paper</a> by <a href=\"https://www.linkedin.com/in/arnd-wussing-8660381\">Arnd Wussing</a>, which explains the topic in much greater detail.</p>\n<h2>Background to Bitemporal</h2>\n<p>The concept of Bi-Temporal Historisation is not new – it was originally associated with a chap called Richard Snodgrass back in 1992. <span style=\"color: #000000;\"><span>There is further info on </span></span><span style=\"color: #0000ff;\"><u><a href=\"http://en.wikipedia.org/wiki/Temporal_database\"><span>Wikipedia</span></a></u></span><span style=\"color: #000000;\"><span> and </span></span><span style=\"color: #0000ff;\"><u><a href=\"http://informix-myview.blogspot.co.uk/2012/03/bitemporal-data-is-this-next-big-thing.html\"><span>this blog</span></a></u></span><span style=\"color: #000000;\"><span>, and a more recent article on <a href=\"https://medium.com/kamu-data/a-brief-history-of-time-in-data-modelling-olap-systems-9032f63b8b7f\">medium</a>.</span></span></p>\n<p class=\"western\"><span style=\"color: #000000;\"><span>Teradata have specifically implemented </span></span><span style=\"color: #0000ff;\"><u><a href=\"smb://smteam.sas.com/DavWWWRoot/psd/rmi/Implementation%20challenges/TeradataBiTemporal.pdf\"><span>temporal features</span></a></u></span><span style=\"color: #000000;\"><span>, which (interestingly) holds the datetime </span></span><span style=\"color: #000000;\"><span><i>pairs</i></span></span><span style=\"color: #000000;\"><span> in a single column (see attachment). Notice the SAS DDS and Teradata nomenclature differences (for SAS DDS: VALID typically means Transaction Datetimes; for Teradata: VALID refers to Business Datetimes).</span></span></p> <a href=\"/wp-content/uploads/2020/08/hist-op_1.1.6_en_manual.pdf\"><img class=\" aligncenter\" src=\"/wp-content/uploads/2020/08/bt.png\" alt=\"bitemporal\" width=\"900\" height=\"102\" /></a> <p class=\"western\"><span style=\"color: #000000;\"> <span>Furthermore, this SUGI paper ( </span></span><span style=\"color: #0000ff;\"><u><a href=\"http://www2.sas.com/proceedings/sugi29/110-29.pdf\"><span>http://www2.sas.com/proceedings/sugi29/110-29.pdf</span></a></u></span><span style=\"color: #000000;\"><span>) covers the issue. Here is an extract (page 8): </span></span></p> <blockquote> <p class=\"western\"><span style=\"color: #000000;\"><span style=\"font-family: ArialMT, Arial, sans-serif;\"><span style=\"font-size: small;\"><span><b>Versioning history</b></span></span></span></span><span style=\"color: #000000;\"><span style=\"font-family: ArialMT, Arial, sans-serif;\"><span style=\"font-size: small;\"><span> (Type Two style) will always require at least a single </span></span></span></span><span style=\"color: #000000;\"><span style=\"font-family: Arial-BoldMT, Arial Bold, sans-serif;\"><span style=\"font-size: small;\"><span><b>updated date </b></span></span></span></span><span style=\"color: #000000;\"><span style=\"font-family: ArialMT, Arial, sans-serif;\"><span style=\"font-size: small;\"><span>for the record, and two </span></span></span></span><span style=\"color: #000000;\"><span style=\"font-family: Arial-BoldMT, Arial Bold, sans-serif;\"><span style=\"font-size: small;\"><span><b>valid from / valid to dates </b></span></span></span></span><span style=\"color: #000000;\"><span style=\"font-family: ArialMT, Arial, sans-serif;\"><span style=\"font-size: small;\"><span>if using a normalized data model. You will also require two dates in a star schema if past point in-time history queries are to be easily run in a single query.</span></span></span></span></p> <p class=\"western\"><span style=\"color: #000000;\"><span style=\"font-family: ArialMT, Arial, sans-serif;\"><span style=\"font-size: small;\"><span><b>Business history</b></span></span></span></span><span style=\"color: #000000;\"><span style=\"font-family: ArialMT, Arial, sans-serif;\"><span style=\"font-size: small;\"><span> may also dictate a need for </span></span></span></span><span style=\"color: #000000;\"><span style=\"font-family: Arial-BoldMT, Arial Bold, sans-serif;\"><span style=\"font-size: small;\"><span><b>effective from / effective to dates </b></span></span></span></span><span style=\"color: #000000;\"><span style=\"font-family: ArialMT, Arial, sans-serif;\"><span style=\"font-size: small;\"><span>when these may differ from the data warehouse versioning dates. This is especially true in certain sectors, like insurance, where value of business is counted over a period rather than a single time. It is also common when such changes are ‘forward-dated’ in operational systems.</span></span></span></span></p> </blockquote> <p class=\"western\">So – enough of the background – what on earth is “Bitemporal Historisation” anyway?</p> <h2 class=\"western\">Bitemporal Historisation - Overview</h2> <p class=\"western\">Once you ‘get it’, the approach is conceptually very simple. There are essentially just TWO datetime pairs to consider:</p> <p class=\"western\"><b>1 – Transaction datetimes.</b> These from/to datetimes show when the <i>warehouse</i> table is populated. They effectively constitute a ‘version number’ for the data. If we want the latest ‘version’ of data, we query using a ‘high datetime’. If we want the version of data which existed yesterday, we query using yesterday’s date. This datetime-pair provides <i>full auditability</i> of results. Note that 99.999% of the time we will always query using the high datetime (current version, latest transactions). This is a standard SCD type 2 loading process. EVERY table must have these datetimes. The rest of this document will use the term 'Transaction' datetimes, to denote when the record was actually transacted, or committed, to the database.</p> <p class=\"western\"><b>2 – Business datetimes</b>. These from/to datetimes show the period to which the data actually relates. NOT every table will have these datetimes – for many queries we are happy to use the <i>current</i> version of, say, a mapping table, even when producing results for historical periods. The rest of this document will use the term ‘Business’ dates.</p> <h2 class=\"western\">Bitemporal Historisation in Detail</h2> The concept of bitemporal historisation relates to the approach of storing both both business (real world) history alongside transaction (version) history in the same table. This approach aims to achieve the following goals: <ul> <li>Queries always produce the same result, even if the data changes</li> <li>Data changes can be audited. Each change is traceable.</li> <li>Existing queries can be easily adapted by adding temporal ranges to the WHERE clause.</li> <li>Programming overhead is reasonable.</li> <li>Historisation rules can be understood by business users.</li> </ul> <p class=\"western\">The goal of query repeatability is particularly important in regulated environments. In order to repeat results reliably, two time points must always be included in the query. An example might be:</p> <p class=\"western\" align=\"center\">“<i>Which motorcyle coverage did Miss Careful have on April 1st, 2020 as we knew it on April 3rd, 2020?”</i></p> <p class=\"western\">- The first date pair represents a business coverage period. This implies that each coverage must have a <strong>BusinessFrom</strong> and <strong>BusinessTo</strong> datetime to show when the coverage starts and finishes.</p> <p class=\"western\">- The second date represents the point in time at which we made (or would have made) the query. Being a snapshot of the database contents, this is termed the “transaction” date. The rest of this document will use <strong>TransactionFrom</strong> and <strong>TransactionTo</strong> for column names.</p> <p class=\"western\">The above query translated into Bitemporal format might look like this:</p>\n<pre class=\"western\" style=\"padding-left: 30px;\">\nSELECT coverage\nFROM customer_coverage_table AS c\nWHERE c.Contact_LName = 'Fudd'\nAND (c.BusinessFrom le '2020-04-01:00:00:00'dt lt c.BusinessTo)\nAND (c.TransactionFrom le '2020-04-03:00:00:00'dt lt c.TransactionTo);\n</pre> <p class=\"western\">Why aren't we using BETWEEN? Because between is <a href=\"https://sqlblog.org/2011/10/19/what-do-between-and-the-devil-have-in-common#:~:text=See%20the%20full%20index.,range%20%E2%80%93%20not%20everyone%20gets%20that.\">evil</a>!</p> <h2 class=\"western\">Bitemporal Prerequisites and Implications</h2> <p class=\"western\">Implementing a bitemporal approach requires a few principles to be adopted.</p> <h3>Records are Never Modified</h3> <p class=\"western\">With the exception of the TransactionTo datetime field (and maybe the PROCESSED_DTTM in the DDS model), once loaded, a record must <strong>never be modified</strong> (or deleted). This would violate the objective of query repeatability.</p> <h3>Matching Close / Open Dates</h3> When a transaction is closed out and re-opened, or if business values are changing over time, the <em>closing</em> datetime must equal the <em>opening</em> datetime. This is to prevent the \"temporal gap\" that can happen when you close out a record at, say, 23:59:59 and re-open it at 00:00:00. What happens if you query at \"23:59:59.5\" ? The data has disappeared!! Note - not all ETL tools have this capability. It's common for an SCD2 load to add a second, or a day, when opening new records. <h3>Business / Transaction FROM must be less than the TO value</h3> Leading on from the previous point, FROM and TO dates cannot be equal, and it also follows that queries should be formed as follows:\n<pre class=\"western\" style=\"padding-left: 30px;\">\nSELECT *\nFROM sometable as t\nWHERE t.pk = 'some key value'\nAND (t.BusinessFrom le &amp;BUSFROM lt t.BusinessTo)\nAND (t.TransactionFrom le &amp;TXFROM lt c.TransactionTo);\n</pre> The above query would always return either 0 or 1 records. It's imperative that there can only be a single record for a particular key value at a particular point in transaction + business time. <h2 class=\"western\">Simple Bitemporal Examples</h2> <p class=\"western\">Looking at the following (dummy) hierarchy, imagine we first loaded a table on 01JAN2019.</p> <p class=\"western\" lang=\"en-GB\"><img class=\"aligncenter size-full \" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-06-22-56-04.png\" alt=\"bitemporal\" width=\"791\" height=\"89\" /></p> <p class=\"western\">In the first case, consider the ERROR in the country code for XYZ Capital. This was spotted on 8th Feb 2019. The table is updated as follows:</p> <p class=\"western\" lang=\"en-GB\"><img class=\"aligncenter size-full \" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-06-22-53-22.png\" alt=\"\" width=\"790\" height=\"106\" /></p> <p class=\"western\">In the second case, lets consider a business change in NAME from \"Crypto Fund\" to \"Doge GmbH\". The need for this change was raised by the actuaries and performed by the IT team on 4th July 2020. However the actual (legal) change in name occurred on 20<sup>th</sup> April 2020. The data is updated as follows:</p> <img class=\"aligncenter size-full \" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-06-22-50-51.png\" alt=\"\" width=\"794\" height=\"150\" /> In this manner, the previous results can always be reproduced (audited), and an \"up to date\" version of past periods can also be generated. <h2>Complex Bitemporal Example</h2> <p class=\"western\">It can be seen that iterative insertions in the bitemporal model are fairly straightforward, but how will it deal with historical restatements?</p> <p class=\"western\">It is noted that ALL historical restatements deal with the scenario of <i>overlapping ranges</i><i><b>.</b></i><b> </b>The most complex of these is the situation below:</p> <p class=\"western\" lang=\"en-GB\"><a href=\"/wp-content/uploads/2020/08/hist-op_1.1.6_en_manual.pdf\"><img class=\"aligncenter size-full \" src=\"/wp-content/uploads/2020/08/bitemporal5.png\" alt=\"bitmporal overlapping\" width=\"705\" height=\"128\" /></a></p> <p class=\"western\" lang=\"en-GB\">The solution is simply to remove the overlap and create three new records:</p> <p class=\"western\" lang=\"en-GB\"><a href=\"/wp-content/uploads/2020/08/hist-op_1.1.6_en_manual.pdf\"><img class=\"aligncenter size-full \" src=\"/wp-content/uploads/2020/08/bitemporal6.png\" alt=\"bitemporal ranges\" width=\"707\" height=\"228\" /></a></p> <p class=\"western\"><span lang=\"en-GB\">Lets see how this would apply to our data. It is decided by the new CFO on 6th August to temporarily rename </span><span lang=\"en-GB\">\"Trust Us Provincial\" to \"So Very Solvent SA\" for the IFRS17 year end results. Who are we to argue!</span></p> <p class=\"western\" lang=\"en-GB\">The table is dutifully updated as follows:<a href=\"/wp-content/uploads/2020/08/hist-op_1.1.6_en_manual.pdf\"><img class=\"aligncenter size-full \" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-06-22-40-55.png\" alt=\"\" width=\"799\" height=\"213\" /></a></p> <p class=\"western\">We simply query the table (for the natural key “3”) where TechnicalTo equals high date. This gave us 1 record. The new record was inserted ‘from’ 31DEC2019. It applied ‘To’ 01JAN2020. There are now 3 records of business history for the current transaction version of that natural key entry.</p> <h2 class=\"western\">Summary</h2> <p class=\"western\">Bi-temporal historisation can solve many date stamping woes and allow safe modifications to business history without affecting auditability (reproducability) of results. This is far more efficient than taking snapshots of the database, and far easier to work with.</p> SAS does not ship with a Bitemporal transform, however - Data Controller does. It also provides full Data Lineage (forwards &amp; reverse, table &amp; column level, including business logic applied). DDS features such as retained keys, PROCESSED_DTTM columns, and of course - SCD2 is also supported. A Data Catalog, Data Dictionary, and DDL generator are also included. We'd love to assist you in your Data Warehousing project - feel free to\n<p><a href=\"/contact/\">get in touch</a>.</p>","fields":{"slug":"/bitemporal-historisation-and-the-sas-dds/"},"frontmatter":{"title":"Bitemporal Historisation and the SAS DDS","date":"August 06, 2020","author":"Allan Bowe","authorLink":"https://www.linkedin.com/in/allanbowe/","previewImg":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/fd57ce9e2506c53f9552ef76dbd2d6f1/c7fad/Screenshot-from-2020-08-06-22-40-55.png","srcSet":"/static/fd57ce9e2506c53f9552ef76dbd2d6f1/c92b0/Screenshot-from-2020-08-06-22-40-55.png 200w,\n/static/fd57ce9e2506c53f9552ef76dbd2d6f1/3d44d/Screenshot-from-2020-08-06-22-40-55.png 400w,\n/static/fd57ce9e2506c53f9552ef76dbd2d6f1/c7fad/Screenshot-from-2020-08-06-22-40-55.png 799w","sizes":"(min-width: 799px) 799px, 100vw"},"sources":[{"srcSet":"/static/fd57ce9e2506c53f9552ef76dbd2d6f1/8459a/Screenshot-from-2020-08-06-22-40-55.webp 200w,\n/static/fd57ce9e2506c53f9552ef76dbd2d6f1/ab8d1/Screenshot-from-2020-08-06-22-40-55.webp 400w,\n/static/fd57ce9e2506c53f9552ef76dbd2d6f1/26f1a/Screenshot-from-2020-08-06-22-40-55.webp 799w","type":"image/webp","sizes":"(min-width: 799px) 799px, 100vw"}]},"width":799,"height":213}}}}}},{"post":{"html":"<h1>What problem does Data Controller for SAS® solve?</h1>\n<div class=\"imgHolder alignright\"><a href=\"https://www.linkedin.com/in/rgagor/\"><img src=\"/wp-content/uploads/2020/07/IMG-20190430-WA0049.jpg\" alt=\"Rafal Gagor - Veteran SAS Developer\" width=\"180\" height=\"180\" /></a><div><span>Rafal Gagor - Veteran SAS Developer</span></div></div>\n<p>It's a question we get asked a lot, and so this is the first of a series of articles that explore real users and their actual use cases. We caught up with <a href=\"https://www.linkedin.com/in/rgagor/\">Rafal Gagor</a>, a DI Developer with 2 decades of SAS and Financial Services experience, to get his impressions after using Data Controller for SAS on a client project.</p>\n<h2>So, Rafal - what did your Client use Data Controller for?</h2>\n<p>Data Controller was implemented initially as the backbone of a <a href=\"https://sasjs.io\">SASjs</a> Release Management system - it allowed my colleagues and I to upload, for each promote, a list of affected SAS artefacts along with details of the release, and associated JIRA tickets. We could make changes directly via the web interface, or by uploading an Excel file. It was great to capture that information automatically in a database and have data quality rules applied at source. The resultant \"clean\" data enabled the delivery of a robust release management web application that saved hours of manual effort each week.</p>\n<h2>Nice use case. How did you manage before you had Data Controller?</h2>\n<p>Previously, release management was a process performed manually and inconsistently, with data scattered across dozens of Excel and Word documents - it was not brought into SAS at all. In the case of other, regular, business-sourced tables that needed to be uploaded - the options were to either hand-craft an upload process manually as a \"one off\" using Enterprise Guide, or to build (and deploy) an ETL flow sourced from an Excel or a CSV file deployed to a network drive.</p>\n<p>This option was problematic - how frequently to run the flow? What if the file format changed? What if the target table changed? It was therefore quite convenient to have the ability to hand such processes back to the data owner, who could safely modify the data within Data Controller without running the risk of overwriting any indexes or otherwise changing the schema of the table.</p>\n<h2>Last question. What were your favourite Data Controller features?</h2>\n<p>Probably my favourite feature was the <strong>Metadata Navigator</strong> - I hadn't been able to use this since moving away from Base SAS quite some years ago. It was useful to be able to navigate through the objects and associations, and view the properties and attributes, without writing any code. Next up was the <strong>Data Lineage</strong> explorer.</p>\n<p>When the business told me there was an issue with a particular field, it was really helpful to use the Data Controller graphical tools - at both table and column level - to perform a reverse (Target to Source) lineage diagram and quickly understand the data flow. This avoided the need to open up every job in DI Studio and explore the transforms.</p>\n<p>Although it's a basic feature, it was great to use the <strong>Data Viewer</strong> to quickly examine and explore the raw tables without locking the datasets (and hence running the risk of stopping a batch run). The full-table search was a neat touch, as well as the DDL export option. Finally, I liked the fact that there were separate buttons for SUBMIT and APPROVE - a bit like a database where you have to commit the change. It's a nice approach that gives an extra layer of validation for the changes uploaded.</p>\n<h2>Rafal - many thanks!</h2>","fields":{"slug":"/data-controller-developer-perspective/"},"frontmatter":{"title":"Data Controller - a Developer Perspective","date":"July 29, 2020","author":"Allan Bowe","authorLink":"https://www.linkedin.com/in/allanbowe/","previewImg":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181818","images":{"fallback":{"src":"/static/3795074afaa91c078996114db15428dc/1696a/IMG-20190430-WA0049.jpg","srcSet":"/static/3795074afaa91c078996114db15428dc/cf6cb/IMG-20190430-WA0049.jpg 63w,\n/static/3795074afaa91c078996114db15428dc/7f937/IMG-20190430-WA0049.jpg 125w,\n/static/3795074afaa91c078996114db15428dc/1696a/IMG-20190430-WA0049.jpg 250w","sizes":"(min-width: 250px) 250px, 100vw"},"sources":[{"srcSet":"/static/3795074afaa91c078996114db15428dc/35c53/IMG-20190430-WA0049.webp 63w,\n/static/3795074afaa91c078996114db15428dc/70f7f/IMG-20190430-WA0049.webp 125w,\n/static/3795074afaa91c078996114db15428dc/af4b8/IMG-20190430-WA0049.webp 250w","type":"image/webp","sizes":"(min-width: 250px) 250px, 100vw"}]},"width":250,"height":300}}}}}}]}},"pageContext":{"page":"category","archives":{"2018":2,"2020":5,"2021":8,"2022":4,"2023":3},"recentPosts":[{"slug":"/v6-1-source-available/","title":"v6.1 Release: Source Available"},{"slug":"/v6-0-api-explorer/","title":"v6.0 Release: Viya API Explorer"},{"slug":"/v5-3-viewboxes/","title":"v5.3 Release: ViewBoxes"},{"slug":"/v5-2-lineage-updates/","title":"v5.2 Release: Lineage Updates"},{"slug":"/v5-1-library-dataset-info/","title":"v5.1 Release: Library & Dataset Info"},{"slug":"/v5-0-column-level-security/","title":"v5.0 Release: Column Level Security"},{"slug":"/v4-0-formats-special-missings/","title":"v4.0 Release: Formats & Special Missings"},{"slug":"/3-13-extended-data-validation/","title":"v3.13 Release: Extended Data Validation and Native Postgres Support"},{"slug":"/saasnow-partnership/","title":"SaasNow Partnership"},{"slug":"/roi-payback/","title":"ROI and Payback"}],"tags":[{"name":"Releases","totalCount":10},{"name":"SAS","totalCount":8},{"name":"Data Lineage","totalCount":5},{"name":"Data Quality","totalCount":5},{"name":"Excel","totalCount":4},{"name":"Use Cases","totalCount":4},{"name":"Regulatory","totalCount":3},{"name":"Data Catalog","totalCount":2},{"name":"Data Management","totalCount":2},{"name":"EUC","totalCount":2}],"filter":{"frontmatter":{"tags":{"in":["SAS"]}}},"limit":6,"skip":0,"numPages":2,"currentPage":1,"tag":"SAS"}},"staticQueryHashes":["615294906"]}