{"componentChunkName":"component---src-templates-blog-list-tsx","path":"/category/regulatory/","result":{"data":{"remark":{"posts":[{"post":{"html":"<h1>ROI and Payback of Data Controller</h1>\n<p>For some customers, the evaluation of a tool is less about the additional value it provides, and more about - will this save me time (and therefore, €€€)?</p>\n<p>By quantifying these savings, it is possible to calculate the rate of return of your investment in Data Controller (ROI) and the Payback period - how long it will take before that investment is effectively recuperated.</p>\n<p>To assist with this process, we will explain all the areas where Data Controller can save time - and finish with a calculator you can use to build your business case internally.</p>\n<h2>#1 - Development Time</h2>\n<p>This represents the time spent designing and preparing the SAS code (or DI Job) that will take a business input and load it into an existing table - be that a database, a dataset, or in-memory CAS.  It could be loaded with a <code>proc import</code>, or an <code>extract</code> transform, or even a full-blown bespoke web application for capturing the particular input requirement.</p>\n<p>It also includes the time spent unit testing that code, documenting any macros, and parameterising it accordingly for the particular input (eg, the network share in which the input file will land).  This time could be spent by multiple stakeholders. To summarise:</p>\n<ul>\n<li>Preparing requirements</li>\n<li>Solution design</li>\n<li>Allocating the development work</li>\n<li>Preparing test data</li>\n<li>Preparing the environment</li>\n<li>Doing the actual development</li>\n<li>Documenting the result</li>\n<li>Code Review</li>\n<li>Writing test Cases</li>\n<li>Running the tests</li>\n</ul>\n<p>With Data Controller, this time is reduced to <strong>zero</strong>.  By taking metadata from the target table (columns, lengths, types, attributes such as NOT NULL) a grid is displayed dynamically into which end users can safely make changes, or drop files such as Excel or CSV with <strong>zero code</strong> (the data is extracted dynamically by JavaScript).</p>\n<h2>#2 - Deployment Time</h2>\n<p>This represents the time taken to move jobs and programs from dev, through other SAS environments such as test, acceptance, and production.  As part of this, it's often necessary to produce release documentation, perform additional deployment steps (such as setup of landing areas, permissions), prepare backout scripts, and perhaps even attend a Change Management meeting to explain the upcoming updates.</p>\n<p>With Data Controller, once installed - this part is reduced to zero.  Unless there was a need to configure a table to be editable in a test / accept environment, it wouldn't need to be done (and if it was, it would be a config change via the interface, not an actual code change).</p>\n<h2>#3 Batch Incidents</h2>\n<p>Quite frequently, when capturing CSVs and Excel files from business users, there can be unintentional changes to the file format or data therein.</p>\n<p>This can play havoc with the batch jobs used to build them, which typically expect a fixed structure, naming convention, directory path, and file type.</p>\n<p>Failures in batch runs take time to troubleshoot and resolve, with knock-on impacts to downstream reporting teams.</p>\n<p>Data Controller sidesteps the problem by ensuring that data is validated on arrival - ie, the user is unable to upload invalid data.  At the same time, the process is flexible enough to ingest data with varying formats, so long as all the necessary columns are provided.</p>\n<p>Batch incidents based on invalid files are therefore avoided.</p>\n<h2>#4 Data Quality Issues</h2>\n<p>For various reasons, data captured regularly from business users, can one day fail to meet quality standards.  This typically creates a whole bunch of work:</p>\n<ul>\n<li>Incident reporting the quality issue</li>\n<li>Creating a new rule for the quality issue</li>\n<li>Testing and deploying the new rule</li>\n<li>Reloading the original data</li>\n</ul>\n<p>Data Controller drastically reduces the time spent on Data Quality with the following features:</p>\n<ul>\n<li>Automatic rules based on the target table schema</li>\n<li>Configurable frontend validations</li>\n<li>Simple and Complex dropdown rules</li>\n<li>Ability to run backend SAS programs for advanced DQ</li>\n</ul>\n<p>In addition, corrections can be made immediately, 'in place', with an approval step and audit trail.</p>\n<h2>#5 Compliance Costs</h2>\n<p>For many regulated clients, the costs of compliance (such as <a href=\"/sarbanes-oxley\">Sarbanes Oxley</a>, BCBS, national <a href=\"/data-quality-and-the-nbb_2017_27-circular\">Data Quality regulations</a>) fall into 3 camps:</p>\n<ul>\n<li>Ongoing (day to day) costs</li>\n<li>Regular (eg annual) audit costs</li>\n<li>Fines (or the risk thereof)</li>\n</ul>\n<p>In terms of data, such costs might come down to storing multiple copies of Excel EUCs on network drives, and the resultant technical debt (extra time) incurred in managing these as the copies mount up during a complex month-end process.</p>\n<p>For audits, especially when performed by external companies, the time spent can be significant.  For end-user computing systems (where source code is not secured) such audits must be <em>reperformed</em> every time, which can get very expensive.</p>\n<p>Examples of fines that have been dealt in the past due to Data Quality or Data Access issues include:</p>\n<ul>\n<li>Morgan Stanley (2020), <a href=\"https://www.cappitech.com/blog/morgan-stanley-fined-5m-for-swap-data-reporting-errors-as-cftc-looks-to-improve-data-quality\">$5 million</a></li>\n<li>Citibank (2020) <a href=\"https://occ.treas.gov/news-issuances/news-releases/2020/nr-occ-2020-132.html\">$400 million</a></li>\n<li>DTCC (2021) <a href=\"https://www.msn.com/en-gb/money/other/eu-securities-watchdog-slaps-dtcc-s-derivatives-unit-in-the-city-with-350k-fine-for-negligence/ar-AAM3u06\">£350k</a></li>\n</ul>\n<p>The benefits of Data Controller in these areas are also threefold:</p>\n<ul>\n<li>Reduced ongoing cost of operation (spreadsheets backed up securely with each dataload)</li>\n<li>Reduce the cost of recertification with clear, controlled on-ramps from EUC to SAS</li>\n<li>Reduced risk of fines through a well documented, IT controlled, Data Governance process</li>\n</ul>\n<p>Unlike desktop based solutions (such as Enterprise Guide), Data Controller secures all code and business logic at the backend in a centralised location - which is far more secure, auditable, and maintainable then the use of local network drives.</p>\n<h2>#6 Data Lineage</h2>\n<p>For SAS customers using Data Integration Studio, a wealth of data lineage is available that maps source systems to target tables and vice versa.</p>\n<p>To surface that information, it is typically necessary to make a request to an ETL developer (with DI Studio), or to step through a large number of connectors in SAS Lineage.</p>\n<p>Data Controller provides both FORWARD and REVERSE lineage diagrams, available directly to all SAS users, that can be exported in PNG, SVG, and CSV formats.</p>\n<h2>#7 Dataset Locks</h2>\n<p>Where end-users are using desktop tools to connect to SAS (eg Base SAS or Enterprise Guide) this can result in table locks preventing updates by other SAS users.</p>\n<p>By using the VIEW menu in Data Controller to examine tables, no locks are held, and hence no processes are disrupted.  In addition, it is possible to share links to tables, even filtered views of those tables.</p>\n<h2>#8 Additional Value</h2>\n<p>Data Controller ships with dozens of <a href=\"https://docs.datacontroller.io/#product-features\">features</a> that help with Data Quality, Data Governance, and Data Management - such as:</p>\n<ul>\n<li>Data Catalog</li>\n<li>Data Dictionary</li>\n<li>Data Alerts</li>\n<li>Data Quality routines</li>\n<li>Data Loading routines</li>\n<li>DDL Exports</li>\n<li>User Navigator</li>\n<li>Metadata Navigator</li>\n<li>Data Model Change Tracking</li>\n</ul>\n<p>We provide a section in the calculator for you to quantify the benefits/savings from having such features.</p>\n<h2>ROI Calculator</h2>\n<p>Download our calculator, and see how much you could save by deploying Data Controller!</p>\n<p><a href=\"/files/DC_ROI_PAYBACK.xlsx\">\n<button>\nDownload\n</button></a></p>","fields":{"slug":"/roi-payback/"},"frontmatter":{"title":"ROI and Payback","date":"July 15, 2021","author":"Allan Bowe","authorLink":"https://www.linkedin.com/in/allanbowe","previewImg":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/a32f554c09bc045fa9b82d212e08060f/6b7ad/roi.jpg","srcSet":"/static/a32f554c09bc045fa9b82d212e08060f/39adf/roi.jpg 1068w,\n/static/a32f554c09bc045fa9b82d212e08060f/fb46a/roi.jpg 2135w,\n/static/a32f554c09bc045fa9b82d212e08060f/6b7ad/roi.jpg 4270w","sizes":"(min-width: 4270px) 4270px, 100vw"},"sources":[{"srcSet":"/static/a32f554c09bc045fa9b82d212e08060f/d583a/roi.webp 1068w,\n/static/a32f554c09bc045fa9b82d212e08060f/163ed/roi.webp 2135w,\n/static/a32f554c09bc045fa9b82d212e08060f/9ee71/roi.webp 4270w","type":"image/webp","sizes":"(min-width: 4270px) 4270px, 100vw"}]},"width":4270,"height":3000}}}}}},{"post":{"html":"<p>The Sarbanes-Oxley Act of 2002 has applied to all publicly-traded companies doing business in the US since 2006. The penalties can be severe - if Uncle Sam considers a corporate officer to have deliberately submitted an inaccurate certification, the corporate fine is $5 million with up to twenty years in prison for the individual(s). Accidental mis-certification (or non-submission) is just $1 million and 10 years in prison.</p>\n<p>There are many aspects to full Sarbanes-Oxley (SOX) compliance, the <a href=\"https://www.govinfo.gov/content/pkg/BILLS-107hr3763enr/pdf/BILLS-107hr3763enr.pdf\">legislation</a> is over 60 pages long. As with other regulatory obligations, the goal is to regularly provide enough evidence to satisfy the auditor that the requirements have been met. As anyone running a compliance team knows, this is no small endeavour. The ability to automate the generation of such evidence, or make it available automatically to auditors, can result in significant cost savings. This article breaks down the areas where Data Controller can contribute to satisfying the requirements of the Sarbanes-Oxley Act.</p>\n<h2>Sarbanes-Oxley Act Section 404 - MANAGEMENT ASSESSMENT OF INTERNAL CONTROLS.</h2>\n<p>Data Controller facilitates internal controls through a 4 eyes review &#x26; approve mechanism for data changes. This, combined with data validation and an integrated workflow feature, provides a mechanism to easily track and report on the number of internal controls (quality rules, signoffs, rejections), as well as the frequency they are applied, who is applying them, which data items the controls relate to, and who is performing them. Such metrics can be compared and contrasted with pre-existing and current quality measures to help determine control effectiveness. Variations in the number of submit / approve cycles between reporting teams, also provide objective and repeatable measurements to support the assessment of the effectiveness of internal controls.</p>\n<div class=\"imgHolder\"><a href=\"https://www.govinfo.gov/content/pkg/BILLS-107hr3763enr/pdf/BILLS-107hr3763enr.pdf\"><img class=\"wp-image-1105 size-full aligncenter\" title=\"Sec 404. (Sarbanes-Oxley)\" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-07-17-57-01.png\" alt=\"Sarbanes Oxley\"/></a><caption>Sarbanes Oxley</caption></div>\n<p>  Section 404 is widely considered the most onerous part of Sarbanes-Oxley, as the documentation and testing of all the controls requires significant time and effort. To address this, the <a href=\"https://pcaobus.org/\">Public Company Accounting Oversight Board</a> (PCAOB - a US non-profit created by the Sarbanes-Oxley act itself) released<a href=\"https://pcaobus.org/Rulemaking/Docket%20021/2007-06-12_Release_No_2007-005A.pdf\"> additional guidance</a> to assist management and auditors in producing their reports. This is officially labeled \"Auditing Standard No. 5 - <em>An Audit of Internal Control Over Financial Reporting That Is Integrated with An Audit of Financial Statements\"</em> A few points are highlighted by the guidance in this standard that are pertinent to users of Data Controller. <h2>PCAOB AS5 Sec24 - Controls Over Management Override</h2> Management Overrides (the freedom to simply \"replace\" reporting figures based on, presumably, sound judgement) are entity level controls that can be easily captured (in a centralised manner) by Data Controller. This in fact, is the \"core functionality\" of the tool. Data Stewards / Data Processors (Editors) make the change, then one or more Data Owners / Data Controllers (Approvers) sign it off before it is applied to the target table. A copy of the original excel file (if used) and a record of who made the change, when, what the change was, and why (if a reason is provided) is recorded. <a href=\"https://docs.datacontroller.io/dcc-validations/\">Data Validation</a> rules can also be defined to ensure that inputs fit the desired pattern(s). <a href=\"https://pcaobus.org/Rulemaking/Docket%20021/2007-06-12_Release_No_2007-005A.pdf\"><img class=\"aligncenter wp-image-1122\" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-10-10-41-12.png\" alt=\"Sarbanes Oxley sas management overrides\" width=\"887\" height=\"409\" /></a> For fun, we made a short video for this part:</p>\n<p><div class=\"gatsby-resp-iframe-wrapper\" style=\"padding-bottom: 56.53333333333334%; position: relative; height: 0; overflow: hidden; margin-bottom: 1.0725rem\" > <div class=\"embedVideo-container\"> <iframe title=\"\" src=\"https://www.youtube.com/embed/iY3KQZL4ok0?rel=0\" class=\"embedVideo-iframe\" style=\"border:0; position: absolute; top: 0; left: 0; width: 100%; height: 100%; \" loading=\"eager\" allowfullscreen=\"\" sandbox=\"allow-same-origin allow-scripts allow-popups\"></iframe> </div> </div></p>\n<p>  <h2>PCAOB AS5 Sec27 - Identifying Entity-Level Controls</h2> <img class=\"aligncenter wp-image-1126\" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-10-12-58-26.png\" alt=\"Sarbanes Oxley SAS Section 24\" width=\"792\" height=\"198\" /> In the area of documenting the inputs, transformations and outputs of data flows within an organisation, SAS particularly shines, especially in the version 9 world. The table and column level lineage generated by SAS Data Integration provides a highly detailed view of the data lineage. Below is an example of Table level lineage, which colour codes each table according to it's library and captures the detail of each SAS job along the way. Clicking on a job will open the job in the metadata viewer. Clicking the table will open the table in VIEW mode. The lineage is shown all the way from source to target(s), or target to source(s) and can be exported in PNG, SVG, or CSV format.</p>\n<div class=\"imgHolder\"><img class=\"aligncenter\" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-10-14-41-04.png\" alt=\"SAS Table Level Lineage Sarbanes Oxley\"/><caption>SAS Table Level Lineage</caption></div>\n<p>Below is an example of column level lineage. Like Table Level lineage, this can be performed forwards or backwards and exported in multiple formats. Each arrow represents a SAS transform. Where business logic is applied, this is additionally extracted and showed in red.</p>\n<div class=\"imgHolder\"><img class=\"aligncenter\" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-10-18-42-50.png\" alt=\"SAS Column Level Lineage Sarbanes Oxley\"/><caption>SAS Column Level Lineage</caption></div>\n<p>  The ability to define additional data lineages, outside of SAS (eg between spreadsheets or other reporting systems) is in the product roadmap, along with lineage from SAS Viya. <h2>PCAOB AS5 App B - Benchmarking of Automated Controls</h2> The use of IT secured financial controls can significantly reduce the cost of Sarbanes-Oxley compliance testing following the first year assessment, particularly where the source code is secured and cannot be modified by users. The core programs (services) within the Data Controller application that perform data signoffs are mature, distinct and change tracked - so it is possible for Data Controller to be upgraded in-place without affecting the benchmarking strategy. This contrasts with spreadsheet based control mechanisms, which must be revalidated in each reporting period.</p>\n<div class=\"imgHolder\"><a href=\"https://pcaobus.org/Rulemaking/Docket%20021/2007-06-12_Release_No_2007-005A.pdf\"><img class=\"aligncenter\" title=\"PCAOB Release 2007-005A, Appendix B\" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-08-22-15-50.png\" alt=\"Sarbanes Oxley SAS\"/></a><caption>PCAOB Release 2007-005A, Appendix B</caption></div>\n<h2>Sarbanes-Oxley Act Section 1102 - Tampering</h2>\n<p>Coming back to the original 2002 SOx paper, there is an additional stick being waved against those who destroy records. This is, unfortunately, a common occurrence in DWh landscapes - poorly designed data models often result in frequent rebuilds of monthly datamarts when issues are found. If your BI / ETL teams are routinely destroying / modifying database records as part of regular work efforts, you might wish to: a) ensure there is a well documented ticketing system to make sure those individuals are protected from any accusations, or b) implement a <a href=\"/bitemporal-historisation-and-the-sas-dds/\">Bitemporal</a> data model to ensure a full and transparent version history of data is always kept regardless of rebuilds. IT-secured tools such as Data Controller enable auditors to see easily for themselves who has changed a record, when, why, and who signed it off - thereby vastly reducing the potential for unintentionally impeding an investigation.</p>\n<div class=\"imgHolder\"><a href=\"/wp-content/uploads/2020/08/BILLS-107hr3763enr.pdf\"><img class=\"aligncenter size-full\" title=\"SEC. 1102. (Sarbanes Oxley)\" src=\"/wp-content/uploads/2020/08/Screenshot-from-2020-08-07-20-18-21.png\" alt=\"sarbanes oxley SAS\"/></a><caption>SEC. 1102. (Sarbanes Oxley)</caption></div>\n<h2>Sarbanes Oxley and SAS</h2>\n<p>We chose SAS as the platform on which to build Data Controller as it is very reliable, provides excellent support for data drivers (enables our code to run inside almost any database), long term customer support, and is very easy to deploy against. The demo version of Data Controller can be <a href=\"https://docs.datacontroller.io/videos/#deploying-data-controller\">deployed in under 30 seconds</a> (on a SAS 9 platform).</p>\n<p>With SAS there are no additional servers to provision, firewalls to configure, scaling issues to address - everything works \"out of the box\". SAS also integrates nicely with existing enterprise authentication mechanisms such as LDAP, and the platform is typically fully secured under your existing IT policies at the backend.</p>\n<p>Data Controller is built on <a href=\"https://sasjs.io\">SASjs</a> and hence we have versions for both SAS 9 and Viya. Do <a href=\"/contact/\">get in touch</a> to learn more.</p>","fields":{"slug":"/sarbanes-oxley/"},"frontmatter":{"title":"Sarbanes-Oxley and Data Controller for SAS©","date":"August 12, 2020","author":"Allan Bowe","authorLink":"https://www.linkedin.com/in/allanbowe/","previewImg":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6bcf8e236f35ef8dddb0bb9907cfbf89/01df5/Screenshot-from-2020-08-10-19-16-01.png","srcSet":"/static/6bcf8e236f35ef8dddb0bb9907cfbf89/85096/Screenshot-from-2020-08-10-19-16-01.png 318w,\n/static/6bcf8e236f35ef8dddb0bb9907cfbf89/4b32c/Screenshot-from-2020-08-10-19-16-01.png 636w,\n/static/6bcf8e236f35ef8dddb0bb9907cfbf89/01df5/Screenshot-from-2020-08-10-19-16-01.png 1272w","sizes":"(min-width: 1272px) 1272px, 100vw"},"sources":[{"srcSet":"/static/6bcf8e236f35ef8dddb0bb9907cfbf89/464fd/Screenshot-from-2020-08-10-19-16-01.webp 318w,\n/static/6bcf8e236f35ef8dddb0bb9907cfbf89/afe36/Screenshot-from-2020-08-10-19-16-01.webp 636w,\n/static/6bcf8e236f35ef8dddb0bb9907cfbf89/24eb4/Screenshot-from-2020-08-10-19-16-01.webp 1272w","type":"image/webp","sizes":"(min-width: 1272px) 1272px, 100vw"}]},"width":1272,"height":718}}}}}},{"post":{"html":"<p>When applying financial regulations in the EU (such as Solvency II, Basel III or GDPR) it is common for Member States to maintain or introduce national provisions to further specify how such rules might be applied. The National Bank of Belgium (NBB) is no stranger to this, and releases a steady stream of circulars via their <a href=\"https://www.nbb.be/en/financial-oversight/general/news/circulars-and-communications\">website</a>. The <a href=\"https://www.nbb.be/doc/cp/eng/2017/20171012_nbb_2017_27.pdf\">circular</a> of 12th October 2017 (NBB_2017_27, Jan Smets) is particularly interesting as it lays out a number of concrete recommendations for Belgian financial institutions with regard to Data Quality - and stated that these should be applied to internal reporting processes as well as the prudential data submitted. This fact is well known by affected industry participants, who have already performed a self assessment for YE2017 and reviewed documentation expectations as part of the HY2018 submission. <h2>Quality of External Data</h2> The DQ requirements for reporting are described by the 6 <a href=\"https://www.nbb.be/doc/cp/eng/2017/20171012_nbb_2017_27_annex.pdf\">dimensions</a> (Accuracy, Reliability, Completeness, Consistency, Plausibility, Timeliness), as well as the Data Quality Framework described by Patrick Hogan <a href=\"https://www.bankingsupervision.europa.eu/press/conferences/sup_rep_conf/shared/pdf/Item4_1_PatrickHogan.pdf\">here</a> and <a href=\"https://www.bankingsupervision.europa.eu/press/conferences/sup_rep_conf/shared/pdf/2017/Data_quality_framework_tools_and_products.pdf\">here</a>. There are a number of 'hard checks' implemented in OneGate as part of the XBRL submissions, which are kept up to date <a href=\"http://www.eba.europa.eu/risk-analysis-and-data/reporting-frameworks\">here</a>. However, OneGate cannot be used as a validation tool - the regulators will be monitoring the <strong>reliability</strong> of submissions by comparing the magnitude of change between resubmissions! Not to mention the data <strong>plausibility</strong> (changes in submitted values over time). <h2>Data Quality Culture</h2> When it comes to internal processes, CRO's across Belgium must now demonstrate to accredited statutory auditors that they satisfy the 3 Principles of the circular (Governance, Technical Capacities, Process). A long list of action points are detailed - it's clear that a <em>lot</em> of documentation will be required to fulfil these obligations! And not only that - the documentation will need to be continually updated and maintained. It's fair to say that automated solutions have the potential to provide significant time &#x26; cost savings in this regard. <h2>Data Controller for SAS®</h2> The Data Controller is a web based solution for capturing data from users. Data Quality is applied at source, changes are routed through an approval process before being applied, and all updates are captured for subsequent audit. The tool provides evidence of compliance with NBB_2017_27 in the following ways: <h4>Separation of Roles for Data Preparation and Validation (principle 1.2)</h4> Data Controller differentiates between Editors (who provide the data) and Approvers (who sign it off). Editors stage data via the web interface, or by direct file upload. Approvers are then shown the new, changed, or deleted records - and can accept or reject the update. <a href=\"/wp-content/uploads/2018/10/Screen-Shot-2018-10-13-at-22.50.56.png\"><img class=\"aligncenter wp-image-962\" src=\"/wp-content/uploads/2018/10/Screen-Shot-2018-10-13-at-22.50.56.png\" alt=\"\" width=\"553\" height=\"296\" /></a></p>\n<h4>Capacities established should ensure compliance in times of stress (principle 2.1)</h4>\nAs an Enterprise tool, the Data Controller is as scalable and resilient as your existing SAS platform.\n<h4>Capture of Errors and Inconsistencies (principle 2.2)</h4> Data Controller has a number of features to ensure timely detection of Data Quality issues at source (such as cell validation, post edit hook scripts, duplicate removals, rejection of data with missing columns, etc etc). Where errors do make it into the system, a full history is kept (logs, copies of files etc) for all uploads and approvals. Emails of such errors can be configured for follow up. <h4>Tools and Techniques for Information Management Should be Automated (principle 2.3)</h4> The Data Controller can be configured to execute specific .sas programs after data validation. This enables the development of a secure and <em>integrated</em> workflow, and helps companies to avoid the additional documentation penalties associated with \"miscellaneous unconnected computer applications\" and manual information processing. <a href=\"/wp-content/uploads/2018/10/Screen-Shot-2018-10-13-at-22.53.38.png\"><img class=\"aligncenter wp-image-963\" src=\"/wp-content/uploads/2018/10/Screen-Shot-2018-10-13-at-22.53.38.png\" alt=\"\" width=\"278\" height=\"128\" /></a> &nbsp; <h4>Periodic Review &amp; Improvements (principles 2.4 and 3.4)</h4> The Data Controller is actively maintained with the specific aim to reduce the cost of compliance with regulations such as NBB_2017_27. Our <a href=\"https://slides.com/allanbowe/datacontroller/#/\">roadmap</a> includes new features such as pre-canned reports, version 'signoff', and the ability to reinstate previous versions of data. <h4>A process for correction and final validation of reporting before submission (3.1)</h4> As a primary and dedicated tool for data corrections, Data Controller can be described once and used everywhere. <h4>List of Divisions Involved in Preparing Tables (principle 3.2)</h4> By using the Data Controller in combination with knowledge of data lineage (eg from SAS metadata or manual lookup table) it becomes possible to produce an automated report to identify exactly who - and hence which division - was involved in both the preparation and the validation of the all source data per reporting table for each reporting cycle. <h4>Processes should integrate and document key controls (principle 3.3)</h4> Data Controller can be used as a staging point for verifying the quality of data, eg when data from one department must be passed to another department for processing. The user access policy will be as per the existing policy for your SAS environment. <h2>Summary</h2> Whilst the circular provides valuable clarity on the expectations of the NBB, there are significant costs involved to prepare for, and maintain, compliance with the guidance. This is especially the case where reporting processes are disparate, and make use of disconnected EUCs and manual processes. The Data Controller for SAS® addresses and automates a number of pain points as specifically described in the circular. It is a robust and easy-to-use tool, actively maintained and <a href=\"http://docs.datacontroller.io\">documented</a>, and provides an integrated solution on a tried and trusted platform for data management. &nbsp;","fields":{"slug":"/data-quality-and-the-nbb_2017_27-circular/"},"frontmatter":{"title":"Data Quality and the NBB_2017_27 Circular","date":"October 13, 2018","author":"Allan Bowe","authorLink":"https://www.linkedin.com/in/allanbowe/","previewImg":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/d63170332d950a898f89eb83659bd803/737e7/download.png","srcSet":"/static/d63170332d950a898f89eb83659bd803/797b9/download.png 113w,\n/static/d63170332d950a898f89eb83659bd803/834e4/download.png 225w,\n/static/d63170332d950a898f89eb83659bd803/737e7/download.png 450w","sizes":"(min-width: 450px) 450px, 100vw"},"sources":[{"srcSet":"/static/d63170332d950a898f89eb83659bd803/34aa2/download.webp 113w,\n/static/d63170332d950a898f89eb83659bd803/b1e24/download.webp 225w,\n/static/d63170332d950a898f89eb83659bd803/8d211/download.webp 450w","type":"image/webp","sizes":"(min-width: 450px) 450px, 100vw"}]},"width":450,"height":111.99999999999999}}}}}}]}},"pageContext":{"page":"category","archives":{"2018":2,"2020":5,"2021":8,"2022":4,"2023":3},"recentPosts":[{"slug":"/v6-1-source-available/","title":"v6.1 Release: Source Available"},{"slug":"/v6-0-api-explorer/","title":"v6.0 Release: Viya API Explorer"},{"slug":"/v5-3-viewboxes/","title":"v5.3 Release: ViewBoxes"},{"slug":"/v5-2-lineage-updates/","title":"v5.2 Release: Lineage Updates"},{"slug":"/v5-1-library-dataset-info/","title":"v5.1 Release: Library & Dataset Info"},{"slug":"/v5-0-column-level-security/","title":"v5.0 Release: Column Level Security"},{"slug":"/v4-0-formats-special-missings/","title":"v4.0 Release: Formats & Special Missings"},{"slug":"/3-13-extended-data-validation/","title":"v3.13 Release: Extended Data Validation and Native Postgres Support"},{"slug":"/saasnow-partnership/","title":"SaasNow Partnership"},{"slug":"/roi-payback/","title":"ROI and Payback"}],"tags":[{"name":"Releases","totalCount":10},{"name":"SAS","totalCount":8},{"name":"Data Lineage","totalCount":5},{"name":"Data Quality","totalCount":5},{"name":"Excel","totalCount":4},{"name":"Use Cases","totalCount":4},{"name":"Regulatory","totalCount":3},{"name":"Data Catalog","totalCount":2},{"name":"Data Management","totalCount":2},{"name":"EUC","totalCount":2}],"filter":{"frontmatter":{"tags":{"in":["Regulatory"]}}},"limit":6,"skip":0,"numPages":1,"currentPage":1,"tag":"Regulatory"}},"staticQueryHashes":["615294906"]}